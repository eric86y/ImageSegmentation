{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8d27c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "from pathlib import Path\n",
    "\n",
    "from Source.Utils import create_dir, generate_dataset, generate_tiled_dataset, generate_masks, sanity_check, split_dataset, split_dataset_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aac8525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset => Images: 93, XML: 93\n",
      "Train => Images: 74, XML: 74\n",
      "Val => Images: 9, XML: 9\n",
      "Test => Images: 10, XML: 10\n"
     ]
    }
   ],
   "source": [
    "### Greate a dataset split if there isn't any\n",
    "data_root = Path(\"D:/Datasets/SortedWesternData/_curatedDataset\")\n",
    "\n",
    "all_images = []\n",
    "all_xml = []\n",
    "\n",
    "\n",
    "for sub_dir in data_root.iterdir():\n",
    "    if \"OK\" in sub_dir.name:\n",
    "        #print(sub_dir)\n",
    "        _images = natsorted(glob(f\"{sub_dir}/*.jpg\"))\n",
    "        _xml = natsorted(glob(f\"{sub_dir}/page/*.xml\"))\n",
    "\n",
    "        assert(len(_images) == len(_xml))\n",
    "\n",
    "        all_images.extend(_images)\n",
    "        all_xml.extend(_xml)\n",
    "\n",
    "\n",
    "print(f\"Dataset => Images: {len(all_images)}, XML: {len(all_xml)}\")\n",
    "\n",
    "sanity_check(all_images, all_xml)\n",
    "\n",
    "train_images, train_xml, val_images, val_xml, test_images, test_xml = split_dataset(all_images, all_xml)\n",
    "\n",
    "assert (len(train_images) == len(train_xml))\n",
    "assert(len(val_images) == len(val_xml))\n",
    "assert(len(test_images) == len(test_xml))\n",
    "\n",
    "\n",
    "print(f\"Train => Images: {len(train_images)}, XML: {len(train_xml)}\")\n",
    "print(f\"Val => Images: {len(val_images)}, XML: {len(val_xml)}\")\n",
    "print(f\"Test => Images: {len(test_images)}, XML: {len(test_xml)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53997735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:06<00:00, 12.13it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 11.90it/s]\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.join(data_root, \"MultiClassDataset\")\n",
    "\n",
    "train_imgs_dir = os.path.join(output_dir, \"train\", \"images\")\n",
    "train_masks_dir = os.path.join(output_dir, \"train\", \"masks\")\n",
    "\n",
    "val_imgs_dir = os.path.join(output_dir, \"val\", \"images\")\n",
    "val_masks_dir  = os.path.join(output_dir, \"val\", \"masks\")\n",
    "\n",
    "test_imgs_dir = os.path.join(output_dir, \"test\", \"images\")\n",
    "test_masks_dir  = os.path.join(output_dir, \"test\", \"masks\")\n",
    "\n",
    "create_dir(train_imgs_dir)\n",
    "create_dir(train_masks_dir)\n",
    "\n",
    "create_dir(val_imgs_dir)\n",
    "create_dir(val_masks_dir)\n",
    "\n",
    "create_dir(test_imgs_dir)\n",
    "create_dir(test_masks_dir)\n",
    "\n",
    "generate_dataset(train_images, train_xml, train_imgs_dir, train_masks_dir)\n",
    "generate_dataset(val_images, val_xml, val_imgs_dir, val_masks_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a2dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [02:24<00:00,  1.96s/it]\n",
      "100%|██████████| 9/9 [00:06<00:00,  1.44it/s]\n",
      "100%|██████████| 10/10 [00:06<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Tiled Dataset\n",
    "\n",
    "output_dir = os.path.join(data_root, \"MultiClassDataset\", \"Tiled_v2\")\n",
    "\n",
    "train_imgs_dir = os.path.join(output_dir, \"train\", \"images\")\n",
    "train_masks_dir = os.path.join(output_dir, \"train\", \"masks\")\n",
    "\n",
    "val_imgs_dir = os.path.join(output_dir, \"val\", \"images\")\n",
    "val_masks_dir  = os.path.join(output_dir, \"val\", \"masks\")\n",
    "\n",
    "test_imgs_dir = os.path.join(output_dir, \"test\", \"images\")\n",
    "test_masks_dir  = os.path.join(output_dir, \"test\", \"masks\")\n",
    "\n",
    "create_dir(train_imgs_dir)\n",
    "create_dir(train_masks_dir)\n",
    "\n",
    "create_dir(val_imgs_dir)\n",
    "create_dir(val_masks_dir)\n",
    "\n",
    "create_dir(test_imgs_dir)\n",
    "create_dir(test_masks_dir)\n",
    "\n",
    "tile_overlap = 0.8\n",
    "\n",
    "generate_tiled_dataset(train_images, train_xml, train_imgs_dir, train_masks_dir, overlap=tile_overlap)\n",
    "generate_tiled_dataset(val_images, val_xml, val_imgs_dir, val_masks_dir, overlap=tile_overlap)\n",
    "generate_tiled_dataset(test_images, test_xml, test_imgs_dir, test_masks_dir, overlap=tile_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e63cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  7.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# individual directory\n",
    "data_root = \"D:/Datasets/SortedWesternData/_curatedDataset\"\n",
    "input_dir = f\"{data_root}/W1PD192038\"\n",
    "overlay = \"no\"\n",
    "annotate_lines = \"yes\"\n",
    "\n",
    "generate_masks(input_dir, annotate_lines, overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d64fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate tiled dataset from pre-created train/val/test distribution based on sub-directories\n",
    "overlay_preview = \"no\"\n",
    "filter_blank = \"no\"\n",
    "precrop = False\n",
    "patch_size = 512\n",
    "dataset_root = \"G:/Datasets/BDRC/_LineLayoutDatasets/LayoutData_Done_LongLines\"\n",
    "data_dir = Path(os.path.join(dataset_root, \"Data\"))\n",
    "\n",
    "output_data_dir = os.path.join(dataset_root, \"Dataset\")\n",
    "\n",
    "distributions = [\"train\", \"test\", \"val\"]\n",
    "\n",
    "filter_for_ok_flag = True\n",
    "\n",
    "for dist in distributions:\n",
    "    \"\"\"\n",
    "    Note that this loop presupposes that each directory has a train, test, and val sub-directory \n",
    "    in which the repsective images and page-xml files are stored.\n",
    "    This is basically for a scenario in which one really wants to hand-craft the individual data splits\n",
    "    to have full control over the the data (e.g. samples with images etc. in each split)\n",
    "    \"\"\"\n",
    "    img_out_dir = os.path.join(output_data_dir, dist, \"Images\")\n",
    "    mask_out_dir = os.path.join(output_data_dir, dist, \"Masks\")\n",
    "\n",
    "    create_dir(img_out_dir)\n",
    "    create_dir(mask_out_dir)\n",
    "               \n",
    "    for sub_dir in data_dir.iterdir():\n",
    "        if \"OK\" in sub_dir.name: # remove that if you want, I just used this to have a handy filter in a directory where the is some wip on the datasets\n",
    "            distribution_path = f\"{sub_dir}/{dist}\"\n",
    "\n",
    "            _images = natsorted(glob(f\"{distribution_path}/*.jpg\"))\n",
    "            _xml = natsorted(glob(f\"{distribution_path}/page/*.xml\"))\n",
    "\n",
    "            assert(len(_images) == len(_xml))\n",
    "\n",
    "            generate_tiled_dataset(_images, _xml, img_out_dir, mask_out_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
