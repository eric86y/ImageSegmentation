{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Python\\ImageSegmentation\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "from Config import MODERN_CLASSES, PERIG_CLASSES\n",
    "\n",
    "from Config import BACKBONES\n",
    "from Source.Utils import create_dir\n",
    "from Source.Trainer import MultiSegmentationTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data => Images: 11540, Masks: 11540\n",
      "Validation data => Images: 1423, Masks: 1423\n",
      "Test data => Images: 1466, Masks: 1466\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"D:/Datasets/SortedWesternData/_curatedDataset/MultiClassDataset/Tiled_v3\"\n",
    "\n",
    "train_data = os.path.join(dataset_path, \"train\")\n",
    "val_data = os.path.join(dataset_path, \"val\")\n",
    "test_data = os.path.join(dataset_path, \"test\")\n",
    "\n",
    "train_x = natsorted(glob(f\"{train_data}/images/*.png\"))\n",
    "train_y = natsorted(glob(f\"{train_data}/masks/*.png\"))\n",
    "\n",
    "valid_x = natsorted(glob(f\"{val_data}/images/*.png\"))\n",
    "valid_y = natsorted(glob(f\"{val_data}/masks/*.png\"))\n",
    "\n",
    "test_x = natsorted(glob(f\"{test_data}/images/*.png\"))\n",
    "test_y = natsorted(glob(f\"{test_data}/masks/*.png\"))\n",
    "\n",
    "print(f\"Training data => Images: {len(train_x)}, Masks: {len(train_y)}\")\n",
    "print(f\"Validation data => Images: {len(valid_x)}, Masks: {len(valid_y)}\")\n",
    "print(f\"Test data => Images: {len(test_x)}, Masks: {len(test_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 512\n",
    "batch_size = 32\n",
    "backbone = BACKBONES[\"mit_b3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Mutliclass Segmentation trainer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Python\\ImageSegmentation\\.venv\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: DiceScore metric currently defaults to `average=micro`, but will change to`average=macro` in the v1.9 release. If you've explicitly set this parameter, you can ignore this warning.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.join(dataset_path, \"Output\")\n",
    "create_dir(output_dir)\n",
    "\n",
    "segmentation_trainer = MultiSegmentationTrainer(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    valid_x,\n",
    "    valid_y,\n",
    "    test_x,\n",
    "    test_y,\n",
    "    image_width=patch_size,\n",
    "    image_height=patch_size,\n",
    "    batch_size=batch_size,\n",
    "    network=\"deeplab\",\n",
    "    backbone=backbone,\n",
    "    output_path=output_dir,\n",
    "    classes=MODERN_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate train loader\n",
    "train_sample = next(iter(segmentation_trainer.train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/12...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [14:50<00:00,  2.47s/it, loss=0.0796]\n",
      "d:\\Projects\\Python\\ImageSegmentation\\Source\\Trainer.py:645: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\autograd\\generated\\python_variable_methods.cpp:837.)\n",
      "  epoch_loss = torch.mean(torch.tensor(epoch_loss))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.18105952441692352, Dice-Score: 0.9548519849777222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [01:28<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Loss: 0.7485092878341675, validation Dice-Score: 0.7534096837043762, Jaccard-Index: 0.2320423722267151\n",
      "Saving Checkpoint to: D:/Datasets/SortedWesternData/_curatedDataset/MultiClassDataset/Tiled_v3\\Output\\2026-1-23_15-46/segmentation_model.pth\n",
      "Epoch: 2/12...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [06:44<00:00,  1.12s/it, loss=0.0899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.10573079437017441, Dice-Score: 0.967117190361023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:42<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Loss: 0.1158519759774208, validation Dice-Score: 0.9654642939567566, Jaccard-Index: 0.7609514594078064\n",
      "Saving Checkpoint to: D:/Datasets/SortedWesternData/_curatedDataset/MultiClassDataset/Tiled_v3\\Output\\2026-1-23_15-46/segmentation_model.pth\n",
      "Epoch: 3/12...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [06:42<00:00,  1.12s/it, loss=0.128] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.09659872204065323, Dice-Score: 0.9694096446037292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:42<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Loss: 0.11145976185798645, validation Dice-Score: 0.9558901190757751, Jaccard-Index: 0.7740395665168762\n",
      "Epoch: 4/12...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [06:44<00:00,  1.12s/it, loss=0.0652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.08952265977859497, Dice-Score: 0.9711000919342041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:46<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Loss: 0.09038770198822021, validation Dice-Score: 0.9639643430709839, Jaccard-Index: 0.805110514163971\n",
      "Epoch: 5/12...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [06:50<00:00,  1.14s/it, loss=0.0613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.08950424939393997, Dice-Score: 0.9708486795425415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:44<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Loss: 0.10193488746881485, validation Dice-Score: 0.9632152915000916, Jaccard-Index: 0.7627487182617188\n",
      "Early stopping training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [01:14<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.04944327101111412, Test Dice-Score: 0.9730848073959351, Jaccard-Index: 0.8192497491836548\n",
      "Saving Training History.... D:/Datasets/SortedWesternData/_curatedDataset/MultiClassDataset/Tiled_v3\\Output\\2026-1-23_15-46/segmentation_model.txt\n",
      "Saved model config to: D:/Datasets/SortedWesternData/_curatedDataset/MultiClassDataset/Tiled_v3\\Output\\2026-1-23_15-46\\model_config.json\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnxscript'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# train mdoel\u001b[39;00m\n\u001b[32m      2\u001b[39m epochs = \u001b[32m12\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43msegmentation_trainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\Python\\ImageSegmentation\\Source\\Trainer.py:726\u001b[39m, in \u001b[36mMultiSegmentationTrainer.train\u001b[39m\u001b[34m(self, epochs, patience, model_name)\u001b[39m\n\u001b[32m    723\u001b[39m         \u001b[38;5;28mself\u001b[39m.save_model_config(filename=model_name)\n\u001b[32m    725\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.export_onnx:\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexport2onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    728\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    730\u001b[39m \u001b[38;5;28mself\u001b[39m.scheduler.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\Python\\ImageSegmentation\\Source\\Trainer.py:587\u001b[39m, in \u001b[36mMultiSegmentationTrainer.export2onnx\u001b[39m\u001b[34m(self, model, model_name, mode, opset)\u001b[39m\n\u001b[32m    582\u001b[39m     model.eval()\n\u001b[32m    583\u001b[39m     model_input = torch.randn(\n\u001b[32m    584\u001b[39m         [\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.classes), \u001b[32m3\u001b[39m, \u001b[38;5;28mself\u001b[39m.image_height, \u001b[38;5;28mself\u001b[39m.image_width], device=\u001b[38;5;28mself\u001b[39m.device\n\u001b[32m    585\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m587\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43monnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_gpu.onnx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    600\u001b[39m     \u001b[38;5;66;03m# TODO: just add cpu export\u001b[39;00m\n\u001b[32m    601\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSkipping onnx export since model is not on the GPU\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\Python\\ImageSegmentation\\.venv\\Lib\\site-packages\\torch\\onnx\\__init__.py:282\u001b[39m, in \u001b[36mexport\u001b[39m\u001b[34m(model, args, f, kwargs, verbose, input_names, output_names, opset_version, dynamo, external_data, dynamic_shapes, custom_translation_table, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, export_params, keep_initializers_as_inputs, dynamic_axes, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[32m    100\u001b[39m \n\u001b[32m    101\u001b[39m \u001b[33;03mSetting ``dynamo=True`` enables the new ONNX export logic\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    279\u001b[39m \u001b[33;03m    *dynamo* is now True by default.\u001b[39;00m\n\u001b[32m    280\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dynamo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, torch.export.ExportedProgram):\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01monnx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_internal\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexporter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _compat\n\u001b[32m    284\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, torch.Tensor):\n\u001b[32m    285\u001b[39m         args = (args,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\Python\\ImageSegmentation\\.venv\\Lib\\site-packages\\torch\\onnx\\_internal\\exporter\\_compat.py:16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01monnx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _constants \u001b[38;5;28;01mas\u001b[39;00m onnx_constants\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01monnx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_internal\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lazy_import\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m onnx, onnxscript_apis, onnxscript_ir \u001b[38;5;28;01mas\u001b[39;00m ir\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01monnx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_internal\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexporter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     _constants,\n\u001b[32m     18\u001b[39m     _core,\n\u001b[32m     19\u001b[39m     _dynamic_shapes,\n\u001b[32m     20\u001b[39m     _onnx_program,\n\u001b[32m     21\u001b[39m     _registration,\n\u001b[32m     22\u001b[39m )\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\Python\\ImageSegmentation\\.venv\\Lib\\site-packages\\torch\\onnx\\_internal\\exporter\\_core.py:18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Mapping, Sequence\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Literal\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnxscript\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnxscript\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluator\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnxscript\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ir\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'onnxscript'"
     ]
    }
   ],
   "source": [
    "# train mdoel\n",
    "epochs = 12\n",
    "segmentation_trainer.train(epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to onnx\n",
    "segmentation_trainer.export2onnx(segmentation_trainer.model, model_name=\"modernbookformat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
